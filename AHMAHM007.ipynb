{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1855a69-2de3-4703-b6ef-5f40543cd444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing key dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec49f6b-fef6-4e28-8d3b-6b6a826668e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_DIR = './data'\n",
    "download_dataset = False\n",
    "\n",
    "# Define transformations for preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize pixel values\n",
    "])\n",
    "\n",
    "# Load MNIST training and test datasets with transformations\n",
    "train_mnist = datasets.MNIST(DATA_DIR, train=True, download=download_dataset, transform=transform)\n",
    "test_mnist = datasets.MNIST(DATA_DIR, train=False, download=download_dataset, transform=transform)\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_mnist, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_mnist, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e96561f-4b1d-4e71-aec5-48f12437fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Loss: 0.39106944037675856\n",
      "Epoch 2/7, Loss: 0.19420943290193876\n",
      "Epoch 3/7, Loss: 0.14348013626684744\n",
      "Epoch 4/7, Loss: 0.11624814991255601\n",
      "Epoch 5/7, Loss: 0.10076662917832534\n",
      "Epoch 6/7, Loss: 0.08720939384798208\n",
      "Epoch 7/7, Loss: 0.07565652132083972\n",
      "Training finished!\n",
      "Model saved as 'mnist_model.pth'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define neural network architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)  # Input layer: 28*28=784, Output layer: 128\n",
    "        self.fc2 = nn.Linear(128, 64)      # Hidden layer: 128, Output layer: 64\n",
    "        self.fc3 = nn.Linear(64, 10)       # Hidden layer: 64, Output layer: 10 (number of classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Flatten input images\n",
    "        x = F.relu(self.fc1(x))  # Apply ReLU activation to the first hidden layer\n",
    "        x = F.relu(self.fc2(x))  # Apply ReLU activation to the second hidden layer\n",
    "        x = self.fc3(x)          # Output layer, no activation as it's included in the loss function\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross entropy loss for classification tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "epochs = 7  # Number of epochs\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader.dataset)}\")\n",
    "    with open('log.txt', 'a') as f:\n",
    "        f.write(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader.dataset)}\\n\")\n",
    "\n",
    "print(\"Training finished!\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'mnist_model.pth')\n",
    "print(\"Model saved as 'mnist_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e525f0-d988-4ef8-92da-ee80a9ba7cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 97.01%\n",
      "Precision on test set: 0.97\n",
      "Recall on test set: 0.97\n",
      "F1-score on test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test set\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_labels.extend(labels.numpy())\n",
    "        predicted_labels.extend(predicted.numpy())\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy on test set: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision on test set: {precision:.2f}\")\n",
    "print(f\"Recall on test set: {recall:.2f}\")\n",
    "print(f\"F1-score on test set: {f1:.2f}\")\n",
    "with open('log.txt', 'a') as f:\n",
    "    f.write(f\"Accuracy on test set: {accuracy * 100:.2f}%\\n\")\n",
    "    f.write(f\"Precision on test set: {precision:.2f}%\\n\")\n",
    "    f.write(f\"Recall on test set: {recall:.2f}%\\n\")\n",
    "    f.write(f\"F1-score on test set: {f1:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a3524-f105-4ca9-9798-a2b73867f127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Open and preprocess the image\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Pass the image through the model\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    \n",
    "    # Get the predicted class\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "# Interactive classification loop\n",
    "while True:\n",
    "    filepath = input(\"Please enter a filepath (or 'exit' to quit): \")\n",
    "    if filepath.lower() == 'exit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    if not os.path.exists(filepath):\n",
    "        print(\"File not found. Please enter a valid filepath.\")\n",
    "        continue\n",
    "    try:\n",
    "        predicted_class = classify_image(filepath)\n",
    "        print(\"Classifier:\", predicted_class)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c0aff5-62b4-45f3-a7ee-f97a694f7c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
